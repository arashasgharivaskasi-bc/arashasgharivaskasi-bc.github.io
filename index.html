<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Arash Asgharivaskasi</title>
  
  <meta name="author" content="Arash Asgharivaskasi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Arash Asgharivaskasi</name>
              </p>
              <p>I am a PhD candidate in the <a href="https://www.ece.ucsd.edu/">Department of Electrical and Computer Engineering</a> at <a href="https://ucsd.edu/">UC San Diego</a>. I work at the <a href="https://existentialrobotics.org/">Existential Robotics Laboratory</a> and have the privilege to be advised by Prof. <a href="https://natanaso.github.io/">Nikolay Atanasov</a>.
              </p>
              <p>
                Before moving to San Diego, I obtained my B.S. degree in Electrical Engineering with a minor in Economics from Sharif University of Technology, Tehran, Iran, in 2018.
              </p>
              <p style="text-align:center">
                <a href="mailto:aasghari@ucsd.edu">Email</a> &nbsp/&nbsp
                <a href="assets/Arash_Asgharivaskasi_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=KgP33s8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
		<a href="https://www.linkedin.com/in/arash-asgharivaskasi-a24083197">LinkedIn Page</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="assets/ArashAsgharivaskasi.jpg"><img style="width:80%;max-width:100%" alt="profile photo" src="assets/ArashAsgharivaskasi.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                The main theme of my research has been active information gathering in the context of robotics. Applications include autonomous exploration and mapping, target tracking, and active 3-D reconstruction. I am interested in using information theory as a bridge between perception models (range sensing, object recognition, etc) and planning methods. Specifically, active information gathering is achieved via finding robot(/sensor) trajectories that optimize an information theoretic objective function based on the sensor's observation model. I am also interested in decentralized multi-robot exploration under non-Euclidean and non-Gaussian regimes.
              </p>
            </td>
          </tr>
        </tbody></table>

       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:-0px;width:30%;vertical-align:top;transform:translate(-10%,7%)">
             <div style="padding:0px">
              <figure><figcaption style="text-align:center">Simulation</figcaption><img src='assets/demo_roam_1.gif' width="265" ></figure>
              <figure><figcaption style="text-align:center">Real-world</figcaption><img src='assets/demo_roam_2.gif' width="265" ></figure>
             </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle;transform:translate(-13.5%,0%)">
              <a href="https://existentialrobotics.org/ROAM_webpage/">
                  <papertitle>Riemannian Optimization for Active Mapping with Robot Teams</papertitle>
              </a>
              <br>
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://www.linkedin.com/in/fritz-girke-9a4a411b6/?originalSubdomain=de">Fritz Girke</a>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>Submitted to IEEE Transactions on Robotics (T-RO), 2024.</em><br>
              <a href="https://existentialrobotics.org/ROAM_webpage/">website</a> /
              <a href="https://youtu.be/EADUWRSkOKs">video</a> /
              <a href="https://arxiv.org/abs/2404.18321">paper</a> /
              <a href="https://github.com/ExistentialRobotics/ROAM">code</a>
              <p>Autonomous exploration of unknown environments using a team of mobile robots demands distributed perception and planning strategies to enable efficient and scalable performance. Ideally, each robot should update its map and plan its motion not only relying on its own observations, but also considering the observations of its peers. Centralized solutions to multi-robot coordination are susceptible to central node failure and require a sophisticated communication infrastructure for reliable operation. Current decentralized active mapping methods consider simplistic robot models with linear-Gaussian observations and Euclidean robot states. In this work, we present a distributed multi-robot mapping and planning method, called Riemannian Optimization for Active Mapping (ROAM). We formulate an optimization problem over a graph with node variables belonging to a Riemannian manifold and a consensus constraint requiring feasible solutions to agree on the node variables. We develop a distributed Riemannian optimization algorithm that relies only on one-hop communication to solve the problem with consensus and optimality guarantees. We show that multi-robot active mapping can be achieved via two applications of our distributed Riemannian optimization over different manifolds: distributed estimation of a 3-D semantic map and distributed planning of SE(3) trajectories that minimize map uncertainty. We demonstrate the performance of ROAM in simulation and real-world experiments using a team of robots with RGB-D cameras.</p>
        </td>
        </tbody></table>
       
       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:0px;width:30%;vertical-align:top;transform:translate(9%,10%)">
             <div style="padding:0px">
              <img src='assets/demo_llm_planning_1.gif' width="225">
              <img src='assets/demo_llm_planning_2.gif' width="225">
             </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <a href="https://existentialrobotics.org/pages/llm-planning.html">
                  <papertitle>Optimal Scene Graph Planning with Large Language Model Guidance</papertitle>
              </a>
              <br>
              <a href="https://daizhirui.github.io/">Zhirui Dai</a>,
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://thaipduong.github.io/">Thai Duong</a>,
              <a href="https://www.linkedin.com/in/shusen-lin-a30495209?originalSubdomain=cn">Shusen Lin</a>,
              <a href="https://www.grasp.upenn.edu/people/mariliza-tzes/">Maria-Elizabeth Tzes</a>,
              <a href="https://www.georgejpappas.org/">George Pappas</a>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>IEEE International Conference on Robotics and Automation (ICRA), 2024.</em><br>
              <a href="https://existentialrobotics.org/pages/llm-planning.html">website</a> /
              <a href="https://youtu.be/dZQnzeGAqzE">video</a> /
              <a href="https://arxiv.org/abs/2309.09182">paper</a> /
              <a href="https://github.com/ExistentialRobotics/LLM-Scene-Graph-LTL-Planning">code</a>
              <p>Recent advances in metric, semantic, and topological mapping have equipped autonomous robots with semantic concept grounding capabilities to interpret natural language tasks. This work aims to leverage these new capabilities with an efficient task planning algorithm for hierarchical metric-semantic models. We consider a scene graph representation of the environment and utilize a large language model (LLM) to convert a natural language task into a linear temporal logic (LTL) automaton. Our main contribution is to enable optimal hierarchical LTL planning with LLM guidance over scene graphs. To achieve efficiency, we construct a hierarchical planning domain that captures the attributes and connectivity of the scene graph and the task automaton, and provide semantic guidance via an LLM heuristic function. To guarantee optimality, we design an LTL heuristic function that is provably consistent and supplements the potentially inadmissible LLM guidance in multi-heuristic planning. We demonstrate efficient planning of complex natural language tasks in scene graphs of virtualized real environments.</p>
        </td>
        </tbody></table>

       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:35px;width:30%;vertical-align:top;transform:translate(7%,0%)">
             <div style="padding:0px">
              <img src='assets/demo_roam_mapping_2.png' width="185">
              <img src='assets/demo_roam_mapping_1.gif' width="200">
             </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <papertitle>Distributed Optimization with Consensus Constraint for Multi-Robot Semantic Octree Mapping</papertitle>
              <br>
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>CoPerception: Collaborative Perception and Learning, ICRA 2023 Workshop.</em><br>
              <a href="https://youtu.be/ZGuEsVOl1e4">video</a> /
              <a href="https://arxiv.org/abs/2402.08867">paper</a> /
              <a href="https://github.com/ExistentialRobotics/ROAM/tree/master/ROAM-Mapping">code</a>
              <p>This work develops a distributed optimization algorithm for multi-robot 3-D semantic mapping using streaming range and visual observations and single-hop communication. Our approach relies on gradient-based optimization of the observation log-likelihood of each robot subject to a map consensus constraint to build a common multi-class map of the environment. This formulation leads to closed-form updates which resemble Bayes rule with one-hop prior averaging. To reduce the amount of information exchanged among the robots, we utilize an octree data structure that compresses the multi-class map distribution using adaptive-resolution.</p>
        </td>
        </tbody></table>
	      
       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top;transform:translate(7%,0%)">
             <div style="padding:35px">
              <img src='assets/demo_ssmi_1.gif' width="150">
              <img src='assets/demo_ssmi_2.gif' width="150">
             </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <a href="https://existentialrobotics.org/SSMI_webpage/">
                  <papertitle>SSMI: Semantic OcTree Mapping and Shannon Mutual Information Computation for Robot Exploration</papertitle>
              </a>
              <br>
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>IEEE International Conference on Robotics and Automation (ICRA), 2021.</em><br>
              <em>Journal version accepted to IEEE Transactions on Robotics (T-RO), 2023.</em><br>
              <a href="https://existentialrobotics.org/SSMI_webpage/">website</a> /
              <a href="https://youtu.be/KosSp3znqFo">video</a> /
              <a href="https://ieeexplore.ieee.org/document/10057106">journal version</a> /
              <a href="https://ieeexplore.ieee.org/abstract/document/9561711">conference version</a> /
              <a href="https://github.com/ExistentialRobotics/SSMI">code</a>
              <p>We develop a Bayesian multiclass mapping algorithm based on an octree data structure, where each voxel maintains a categorical distribution over semantic classes. We derive a closed-form efficiently computable lower bound of the Shannon mutual information between a multiclass octomap and a set of range-category measurements using semantic run-length encoding of the sensor rays. The bound allows rapid evaluation of many potential robot trajectories for autonomous exploration and mapping. We compare our method against state-of-the-art exploration techniques and apply it in a variety of simulated and real-world experiments.</p>
        </td>
        </tbody></table>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top;transform:translate(5%,0%)">
             <div style="padding:35px">
              <img src='assets/demo_l4dc_1.gif' width="150" style="transform:translate(-1%,0%)">
              <img src='assets/demo_l4dc_2.gif' width="150">
             </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <papertitle>Policy Learning for Active Target Tracking over Continuous SE (3) Trajectories</papertitle>
              <br>
              <a href="https://pengzhi1998.github.io/">Pengzhi Yang</a>,
              <a href="https://shumon0423.github.io/">Shumon Koga</a>,
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>Learning for Dynamics and Control (L4DC), 2023.</em><br>
              <a href="https://proceedings.mlr.press/v211/yang23a">paper</a>
              <p>We propose a novel model-based policy gradient algorithm for tracking dynamic targets using a mobile robot, equipped with an onboard sensor with limited field of view. The task is to obtain a continuous control policy for the mobile robot to collect sensor measurements that reduce uncertainty in the target states, measured by the target distribution entropy. We design a neural network control policy with the robot <em>SE(3)</em> pose and the mean vector and information matrix of the joint target distribution as inputs and attention layers to handle variable numbers of targets. We also derive the gradient of the target entropy with respect to the network parameters explicitly, allowing efficient model-based policy gradient optimization.</p>
        </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td style="padding:20px;width:30%;vertical-align:top;transform:translate(5%,-2%)">
            <div style="padding:20px">
                <div style="display:flex;justify-content:center;transform:translate(-2.4%,0%)">
                <img src='assets/demo_icra23_learning_1.gif' width="59">
                <img src='assets/demo_icra23_learning_2.gif' width="59">
                <img src='assets/demo_icra23_learning_3.gif' width="59">
                </div>
                <img src='assets/demo_icra23_learning_4.gif' width="180">
            </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <papertitle>Learning Continuous Control Policies for Information-Theoretic Active Perception</papertitle>
              <br>
              <a href="https://pengzhi1998.github.io/">Pengzhi Yang</a>,
              <a href="https://jaysparrow.github.io/">Yuhan Liu</a>,
              <a href="https://shumon0423.github.io/">Shumon Koga</a>,
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>IEEE International Conference on Robotics and Automation (ICRA), 2023.</em><br>
              <a href="https://ieeexplore.ieee.org/document/10160455">paper</a> /
              <a href="https://github.com/JaySparrow/RL-for-active-mapping">code</a>
              <p>We consider a mobile robot detecting landmarks within a limited sensing range, and tackle the problem of learning a model-free control policy that maximizes the mutual information between the landmark states and the sensor observations. We employ a Kalman filter to convert the partially observable problem in the landmark state to Markov decision process (MDP), a differentiable field of view to shape the reward, and an attention-based neural network to represent the control policy. The approach is further unified with active volumetric mapping to promote exploration in addition to landmark localization. The performance is demonstrated in several simulated landmark localization tasks in comparison with benchmark methods.</p>
        </td>
        </tbody></table>

				<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top">
              <img src='assets/demo_icra23_GT.jpg' width="220">
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <papertitle>Information-theoretic Abstraction of Semantic Octree Models for Integrated Perception and Planning</papertitle>
              <br>
              Daniel T. Larsson,
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://jliminf.github.io/">Jaein Lim</a>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>,
              <a href="https://dcsl.gatech.edu/tsiotras.html">Panagiotis Tsiotras</a>
              <br>
              <em>IEEE International Conference on Robotics and Automation (ICRA), 2023.</em><br>
              <a href="https://ieeexplore.ieee.org/document/10160407">paper</a>
              <p></p>
              <p>Our approach builds a three-dimensional, semantic tree representation of the environment from sensor data which is then compressed by a novel information-theoretic tree-pruning approach. The proposed approach is probabilistic and incorporates the uncertainty in semantic classification inherent in real-world environments. Moreover, our approach allows robots to prioritize individual semantic classes when generating the compressed trees, so as to design multi-resolution representations that retain the relevant semantic information while simultaneously discarding unwanted semantic categories. We demonstrate the approach by compressing semantic octree models of a large outdoor, semantically rich, real-world environment. In addition, we show how the octree abstractions can be used to create semantically-informed graphs for motion planning, and provide a comparison of our approach with uninformed graph construction methods such as Halton sequences.</p>
        </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top;transform:translate(0%,0%)">
             <div style="padding:0px">
              <img src='assets/demo_iros22_1.jpg' width="220">
              <img src='assets/demo_iros22_2.jpg' width="220">
              <img src='assets/demo_iros22_3.jpg' width="220">
             </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <a href="https://arashasgharivaskasi-bc.github.io/grad_active_mapping/">
                  <papertitle>Active Mapping via Gradient Ascent Optimization of Shannon Mutual Information over Continuous <em>SE(3)</em> Trajectories</papertitle>
              </a>
              <br>
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://shumon0423.github.io/">Shumon Koga</a>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022.</em><br>
              <a href="https://arashasgharivaskasi-bc.github.io/grad_active_mapping/">website</a> /
              <a href="https://youtu.be/UIjr5dVngfc">video</a> /
              <a href="https://ieeexplore.ieee.org/abstract/document/9981875">paper</a>
              <p></p>
              <p>The non-smooth nature of ray-tracing within a grid representation makes the active mapping objective function non-differentiable, forcing existing methods to search over a discrete space of candidate trajectories. This work proposes a differentiable approximation of the Shannon mutual information between a grid map and ray-based observations that enables gradient ascent optimization in the continuous space of <em>SE(3)</em> sensor poses. Our gradient-based formulation leads to more informative sensing trajectories, while avoiding occlusions and collisions. The proposed method is demonstrated in simulated and real-world experiments in 2-D and 3-D environments.</p>
        </td>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top;transform:translate(0%,0%)">
             <div style="padding:10px">
              <img src='assets/demo_icr_lqr.png' width="200">
             </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <papertitle>Active SLAM over Continuous Trajectory and Control: A Covariance-Feedback Approach</papertitle>
              <br>
              <a href="https://shumon0423.github.io/">Shumon Koga</a>,
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>American Control Conference (ACC), 2022.</em><br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9867507">paper</a>
              <p></p>
              <p>We propose a novel active Simultaneous Localization and Mapping (SLAM) method with continuous trajectory optimization over a stochastic robot dynamics model. The problem is formalized as a stochastic optimal control over the continuous robot kinematic model to minimize a cost function that involves the covariance matrix of the landmark states. We tackle the problem by separately obtaining an open-loop control sequence subject to deterministic dynamics by iterative Covariance Regulation (iCR) and a closed-loop feedback control under stochastic robot and covariance dynamics by Linear Quadratic Regulator (LQR). The proposed optimization method captures the coupling between localization and mapping in predicting uncertainty evolution and synthesizes highly informative sensing trajectories. We demonstrate its performance in active landmark-based SLAM using relative-position measurements with a limited field of view.</p>
        </td>
        </tbody></table>
				
				<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
             <td style="padding:20px;width:30%;vertical-align:top;transform:translate(5%,-1%)">
             <div style="padding:45px">
              <img src='assets/demo_iros21_1.gif' width="130">
              <img src='assets/demo_iros21_2.gif' width="130">
             </div>
            </td>

        <td style="padding:20px;width:80%;vertical-align:middle">
              <a href="https://shumon0423.github.io/IROS2021_webpage/">
                  <papertitle>Active Exploration and Mapping via Iterative Covariance Regulation over Continuous <em>SE(3)</em> Trajectories</papertitle>
              </a>
              <br>
              <a href="https://shumon0423.github.io/">Shumon Koga</a>,
              <strong>Arash Asgharivaskasi</strong>,
              <a href="https://natanaso.github.io/">Nikolay Atanasov</a>
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021.</em><br>
              <a href="https://shumon0423.github.io/IROS2021_webpage/">website</a> /
              <a href="https://youtu.be/Qgt64a0bOiA">video</a> /
              <a href="https://ieeexplore.ieee.org/abstract/document/9636486">paper</a>
              <p></p>
              <p>This paper develops iterative Covariance Regulation (iCR), a novel method for active exploration and mapping for a mobile robot equipped with on-board sensors. The problem is posed as optimal control over the <em>SE(3)</em> pose kinematics of the robot to minimize the differential entropy of the map conditioned on the potential sensor observations. We introduce a differentiable field of view formulation, and derive iCR via the gradient descent method to iteratively update an open-loop control sequence in continuous space so that the covariance of the map estimate is minimized. We demonstrate autonomous exploration and uncertainty reduction in simulated occupancy grid environments.</p>
        </td>
        </tbody></table>
				
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://clustrmaps.com/site/1btvi"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=dVp09l5OjNFBGvvLPq0kvCAavEsVuJ0Cvp8DN-SWuko&cl=ffffff" /></a>
                <br /> 
                Template borrowed from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
